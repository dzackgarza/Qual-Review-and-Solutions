\input{"/home/zack/Dropbox/Document Archive/Latex/preamble.tex"}
\let\Begin\begin
\let\End\end
\newcommand\wrapenv[1]{#1}

\makeatletter
\def\ScaleWidthIfNeeded{%
 \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\def\ScaleHeightIfNeeded{%
  \ifdim\Gin@nat@height>0.9\textheight
    0.9\textheight
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\setkeys{Gin}{width=\ScaleWidthIfNeeded,height=\ScaleHeightIfNeeded,keepaspectratio}%

\title{
\textbf{
    Analysis Qual Solutions
  }
  }
\author{D. Zack Garza}
\date{\today}

\begin{document}

\maketitle
% \todo{Insert title and subtitle.}
\tableofcontents


\hypertarget{fall-2019}{%
\section{Fall 2019}\label{fall-2019}}

\hypertarget{section}{%
\subsection{1}\label{section}}

\begin{quote}
Cesaro mean/summation. Break series apart into pieces that can be
handled separately.
\end{quote}

\hypertarget{a}{%
\subsection{a}\label{a}}

Prove a stronger result:
\begin{align*}
a_n \to A \implies \frac 1 N \sum^N a_k \to A
.\end{align*}

\begin{quote}
Idea: once \(N\) is large enough, \(a_k \approx A\), and all smaller
terms will die off as \(N\to \infty\).

See
\href{https://math.stackexchange.com/questions/514802/convergence-of-series-implies-convergence-of-cesaro-mean}{this
MSE answer}.
\end{quote}

Suppose \(S_k \to S\). Choose \(\ell\) large enough such that
\begin{align*}
k\geq \ell \implies \abs{S_k - S} < \varepsilon
.\end{align*}

With \(\ell\) fixed, choose \(N\) large enough such that
\begin{align*}
k\leq \ell \implies \frac{\left|S_{k}-S\right|}{N} < \varepsilon
.\end{align*}

Then \begin{align*}
\left|\left(\frac{1}{N} \sum_{k=1}^{N} S_{k}\right)-S\right| 
&=\frac{1}{N}\left|\sum_{k=1}^{N}\left(S_{k}-S\right)\right| \\
&\leq \frac{1}{N} \sum_{k=1}^{N}\left|S_{k}-S\right| \\
&= \sum_{k=1}^{\ell}\frac{\left|S_{k}-S\right|}{N} +
\sum_{k=\ell+1}^{N} \frac{\left|S_{k}-S\right|}{N} \\
& \to 0
.\end{align*}

\hypertarget{b}{%
\subsection{b}\label{b}}

Define \begin{align*}
\Gamma_n \definedas \sum_{k=n}^\infty \frac{a_k}{k}
.\end{align*}

Then \(\Gamma_1 = \sum_k \frac{ a_k } k\) and each \(\Gamma_n\) is a
tail of this series, so by assumption \(\Gamma_n \to 0\).

Then \begin{align*}
\frac 1 n \sum_{k=1}^n a_k 
&= \frac 1 n (\Gamma_0 + \Gamma_1 + \cdots + \Gamma_{n} \mathbf{- \Gamma_{n+1}}) \\
&\to 0
.\end{align*}

This comes from consider the following summation:

\begin{tikzcd}
\Gamma_1:&\arrow[dash, ddddd]   & a_1 & + \frac{a_2}{2} & + \frac{a_3}{3} & + \cdots &     &                                    &          &  &  &  \\
\Gamma_2:                                                       &               &     & \frac{a_2}{2}   & + \frac{a_3}{3} & + \cdots &     &                                    &          &  &  &  \\
\Gamma_3:                                                       &               &     &                 & \frac{a_3}{3}   & + \cdots &     &                                    &          &  &  &  \\
 \arrow[dash, rrrrrrrrrr] &&&&&&&&&&{}&   \\
\sum_{i=1}^n \Gamma_i:                                          &               & a_1 & +a_2            & +a_3            & + \cdots & a_n & + \frac{a_{n+1}}{n+1}              & + \cdots &  &  &  \\
& {}               &     &                 &                 &          &     &   &          &  &  & 
\end{tikzcd}

\(\qed\)

\hypertarget{section-1}{%
\subsection{2}\label{section-1}}

\begin{quote}
DCT, and bounding in the right place. Don't evaluate the actual
integral!
\end{quote}

Use the fact that \(\int_0^1 \cos(tx) ~dt = \sin(x)/x\), then
\begin{align*}
\abs {\dd{^n}{x} \sin(x)/x  }
&= \abs { \dd{^n}{x}\int_0^1 \cos(tx)~dt }\\
&=_? \abs{ \int_0^1  \dd{^n}{x} \cos(tx)~dt }\\
&= \abs{ \int_0^1 -t^n \sin(tx) ~dt } \quad \text{for $n$ odd}\\
&\leq \int_0^1 \abs{t^n \sin(tx)} ~dt \\
&\leq \int_0^1 t^n ~dt \\ 
&= \frac{1}{n+1} \\
&< \frac{1}{n}
.\end{align*}

Where the DCT is justified by noting that \(f(t) = \cos(tx)\) is
dominated by \(g(t) = 1\) on \([0, 1]\), which integrates to 1.

\(\qed\)

\hypertarget{section-2}{%
\subsection{3}\label{section-2}}

\begin{quote}
Borel-Cantelli.

Use the following observation: for a sequence of sets \(X_n\),

\begin{align*}
\limsup_n X_n &= \theset{x \suchthat x\in X_n \text{ for infinitely many $n$} } 
&= \intersect_{m\in \NN} \union_{n\geq m} X_n
\\
\liminf_n X_n &= \theset{x \suchthat x\in X_n \text{ for all but finitely many $n$} }
&= \union_{m\in \NN} \intersect_{n\geq m} X_n
.\end{align*}

And recall

\begin{align*}
\prod_n e^{x_n} = e^{\sum_n x_n} \quad\text{and} \quad \sum_n \log(x_n) = \log\left(\prod_n x_n\right)
.\end{align*}
\end{quote}

\hypertarget{a-1}{%
\subsubsection{a}\label{a-1}}

The Borel \(\sigma\dash\)algebra is closed under countable
unions/intersections/complements, and \(B = \limsup_n B_n\) is an
intersection of unions of measurable sets.

\hypertarget{b-1}{%
\subsubsection{b}\label{b-1}}

We'll use the fact that tails of convergent sums go to zero, so
\(\sum_{n\geq M} \mu(B_n) \mapsvia{M\to\infty} 0\), and
\(B_M \definedas \intersect_{m = 1}^M \union_{n\geq m} B_n \searrow B\).

\begin{align*}
\mu(B_M) 
&= \mu\left(\intersect_{m\in \NN} \union_{n\geq m} B_n\right) \\
&\leq \mu\left( \union_{n\geq m} B_n \right) \quad \text{for all } m\in \NN \\
&\to 0
,\end{align*}

and the result follows by continuity of measure.

\hypertarget{c}{%
\subsubsection{c}\label{c}}

To show \(\mu(B) = 1\), we'll show \(\mu(B^c) = 0\).

Let \(B_k = \intersect_{m=1}^\infty \union_{n = m}^K B_n\). Then

\begin{align*}
\mu(B_K^c) 
&= \mu \left(\union_{m=1}^\infty \intersect_{n=m}^K B_n^c\right) \\
&\leq \sum_{m=1}^\infty \mu\left( \intersect_{n=m}^K B_n^c \right) \quad\text{ by subadditivity} \\
&= \sum_{m=1}^\infty \prod_{n=m}^K 1 - \mu(B_n) \\
&\leq \sum_{m=1}^\infty \prod_{n=m}^K e^{-\mu(B_n^c)} \quad\text{by hint} \\
&= \sum_{m=1}^\infty e^{-\sum_{n=m}^K \mu(B_n^c)} \\
&\to 0
\end{align*}

since \(\displaystyle\sum_{n=m}^K \mu(B_n^c) \to \infty\), and we can
apply continuity of measure since \(B_K^c \mapsvia{K\to\infty} B^c\).

\(\qed\)

\hypertarget{section-3}{%
\subsection{4}\label{section-3}}

\begin{quote}
Bessel's Inequality, surjectivity of Riesz map, and Parseval's Identity.

Trick -- remember to write out finite sum \(S_N\), and consider
\(\norm{x - S_N}\).
\end{quote}

\hypertarget{a-2}{%
\subsubsection{a}\label{a-2}}

\textbf{Claim:} \begin{align*}
0 \leq \left\|x-\sum_{n=1}^{N}\left\langle x, u_{n}\right\rangle u_{n}\right\|^{2}
&= \|x\|^{2}-\sum_{n=1}^{N}\left|\left\langle x, u_{n}\right\rangle\right|^{2} \\ 
&\implies
\sum_{n=1}^{\infty}\left|\left\langle x, u_{n}\right\rangle\right|^{2} \leq\|x\|^{2}
.\end{align*}

\emph{Proof:} Let \(S_N = \sum_{n=1}^N \inner{x}{u_n} u_n\). Then
\begin{align*}
0 
&\leq \norm{x - S_N}^2 \\ 
&= \inner{x - S_n}{x - S_N} \\
&= \norm{x}^2 - \sum_{n=1}^N \abs{\inner{x}{u_n}}^2 \\
&\mapsvia{N\to\infty} \norm{x}^2 - \sum_{n=1}^N \abs{\inner{x}{u_n}}^2
.\end{align*}

\hypertarget{b-2}{%
\subsubsection{b}\label{b-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Fix \(\theset{a_n} \in \ell^2\), then note that
  \(\sum \abs{a_n}^2 < \infty \implies\) the tails vanish.
\item
  Define
  \begin{align*}
  x \definedas \displaystyle\lim_{N\to\infty} S_N = \lim_{N\to \infty} \sum_{k=1}^N a_k u_k
  \end{align*}
\item
  \(\theset{S_N}\) Cauchy (by 1) and \(H\) complete \(\implies x\in H\).
\item

  \begin{align*}
  \inner{x}{u_n} = \inner{\sum_k a_k u_k}{u_n} = \sum_k a_k \inner{u_k}{u_n} = a_n \quad \forall n\in \NN
  \end{align*} since the \(u_k\) are all orthogonal.
\item

  \begin{align*}
  \norm{x}^2 = \norm{\sum_k a_k u_k}^2 = \sum_k \norm{a_k u_k}^2 = \sum_k \abs{a_k}^2
  \end{align*} by Pythagoras since the \(u_k\) are normal.
\end{enumerate}

\begin{quote}
Bonus: We didn't use completeness here, so the Fourier series may not
actually converge to \(x\). If \(\theset{u_n}\) is \textbf{complete} (so
\(x = 0 \iff \inner{x}{u_n} = 0 ~\forall n\)) then the Fourier series
\emph{does} converge to \(x\) and
\(\sum_{n=1}^{\infty}\left|\left\langle x, u_{n}\right\rangle\right|^{2}=\|x\|^{2}\)
for all \(x \in H\).
\end{quote}

\(\qed\)

\hypertarget{section-4}{%
\subsection{5}\label{section-4}}

\begin{quote}
Continuity in \(L^1\) (recall that DCT won't work! Notes 19.4, prove it
for a dense subset first).

Lebesgue differentiation in 1-dimensional case. See HW 5.6.
\end{quote}

\hypertarget{a-3}{%
\subsection{a}\label{a-3}}

Choose \(g\in C_c^0\) such that \(\norm{f- g}_1 \to 0\).

By translation invariance, \(\norm{\tau_h f - \tau_h g}_1 \to 0\).

Write \begin{align*}
\norm{\tau f - f}_1 
&= \norm{\tau_h f - g + g - \tau_h g + \tau_h g - f}_1 \\
&\leq \norm{\tau_h f - \tau_h g} + \norm{g - f} + \norm{\tau_h g - g} \\
&\to \norm{\tau_h g - g}
,\end{align*}

so it suffices to show that \(\norm{\tau_h g - g} \to 0\) for
\(g\in C_c^0\).

Fix \(\varepsilon > 0\). Enlarge the support of \(g\) to \(K\) such that
\begin{align*}
\abs{h} \leq 1 \text{ and } x \in K^c \implies \abs{g(x-h) - g(x)} = 0
.\end{align*}

By uniform continuity of \(g\), pick \(\delta \leq 1\) small enough such
that
\begin{align*}
x\in K, ~\abs{h} \leq \delta \implies \abs{g(x-h) -g(x)} < \varepsilon
,\end{align*}

then
\begin{align*}
\int_K \abs{g(x-h) - g(x)} \leq \int_K \varepsilon = \varepsilon \cdot m(K) \to 0.
\end{align*}

\hypertarget{b-3}{%
\subsection{b}\label{b-3}}

We have \begin{align*}
\int_\RR \abs{A_h(f)(x)} ~dx 
&= \int_\RR \abs{\frac{1}{2h} \int_{x-h}^{x+h} f(y)~dy} ~dx \\
&\leq \frac{1}{2h} \int_\RR \int_{x-h}^{x+h} \abs{f(y)} ~dy ~dx    \\
&=_{FT} \frac{1}{2h} \int_\RR \int_{y-h}^{y+h} \abs{f(y)} ~\mathbf{dx} ~\mathbf{dy}    \\
&= \int_\RR \abs{f(y)} ~{dy} \\
&= \norm{f}_1
.\end{align*}

and (rough sketch)

\begin{align*}
\int_\RR \abs{A_h(f)(x) - f(x)} ~dx 
&= \int_\RR \abs{ \left(\frac{1}{2h} \int_{B(h, x)} f(y)~dy\right) - f(x)}~dx \\
&= \int_\RR \abs{ \left(\frac{1}{2h} \int_{B(h, x)} f(y)~dy\right) - \frac{1}{2h}\int_{B(h, x)} f(x) ~dy}~dx \\
&\leq_{FT} \frac{1}{2h} \int_\RR  \int_{B(h, x)}\abs{ f(y-x) - f(x)} ~\mathbf{dx} ~\mathbf{dy} \\
&\leq \frac 1 {2h} \int_\RR \norm{\tau_x f - f}_1 ~dy \\
&\to 0 \quad\text{by (a)}
.\end{align*}

\(\qed\)

\hypertarget{spring-2019}{%
\section{Spring 2019}\label{spring-2019}}

\hypertarget{section}{%
\subsection{1}\label{section}}

\hypertarget{a}{%
\subsubsection{a}\label{a}}

Let \(\theset{f_k}\) be a Cauchy sequence in \(C(I)\). For each fixed
\(x\in [0, 1]\), the sequence of real numbers \(\theset{f_k(x)}\) is
Cauchy in \(\RR\), which is complete, since
\begin{align*}
x_0\in I \implies \abs{f_k(x_0) - f_j(x_0)} \leq \sup_{x\in I} \abs{f_k(x) - f_j(x)} = \norm{f_k - f_j}_\infty \to 0,
\end{align*}

so we can define \(f(x) \definedas \lim_k f_k(x)\).

We also have \begin{align*}
\norm{f_k - f}_\infty
= \norm{f_k - \lim_{j\to\infty} f_j}_\infty 
= \lim_{j\to\infty} \norm{f_k - f_j}_\infty 
\to 0
.\end{align*}

Finally, \(f\) is the uniform limit of continuous functions and thus
continuous.

\(\qed\)

\hypertarget{b}{%
\subsubsection{b}\label{b}}

It suffices to produce a Cauchy sequence that does not converge to a
continuous function. Take \begin{align*}
f_k(x) = 
\begin{cases}
(x + \frac 1 2)^k & x \in [0, \frac 1 2) \\
1 & x \in [\frac 1 2, 1]
\end{cases}
\quad \mapsvia{k\to\infty} \quad
f(x) = 
\begin{cases}
0 & x \in [0, \frac 1 2) \\
1 & x \in [\frac 1 2, 1]
\end{cases}
,\end{align*}

which is Cauchy, but there is no \(g\in L^1\) that is continuous such
that \(\norm{f - g}_1 = 0\).

\hypertarget{section-1}{%
\subsection{2}\label{section-1}}

\hypertarget{a-1}{%
\subsubsection{a}\label{a-1}}

\begin{quote}
Lemma 1:
\(\mu(\disjoint_{k=1}^\infty E_k) = \lim_{N\to\infty} \sum_{k=1}^N \mu(E_k)\).

Lemma 2: \(A = A\setminus B ~\disjoint~ A\intersect B\).
\end{quote}

Let \(A_k = F_k \setminus F_{k+1}\), so the \(A_k\) are disjoint, and
let \(A = \disjoint_k A_k\).

Let \(F = \intersect_k F_k\). Then \(F_1 = F \disjoint A\) by lemma 2,
so \begin{align*}
\mu(F_1) 
&= \mu(F) + \mu(A) \\
&= \mu(F) + \lim_{N\to\infty} \sum_k^N \mu(A_k) \quad \text{by Lemma 1}\\
&= \mu(F) + \lim_{N\to\infty} \sum_k^N \mu(F_k) - \mu(F_{k+1}) \\
&= \mu(F) + \lim_{N\to\infty} \left( \mu(F_1) - \mu(F_N) \right) \quad\text{(Telescoping)} \\
&=\mu(F) + \mu(F_1) - \lim_{N\to\infty} \mu(F_N)
,\end{align*}

and since the measure is finite, \(\mu(F_1) < \infty\) and can be
subtracted, yielding \begin{align*}
\mu(F_1) &= \mu(F) + \mu(F_1) - \lim_{N\to\infty} \mu(F_N) \\
\implies \mu(F) &= \lim_{N\to\infty} \mu(F_N)
.\end{align*}

\hypertarget{b-1}{%
\subsubsection{b}\label{b-1}}

Suppose toward a contradiction that there is some \(\varepsilon > 0\)
for which no such \(\delta\) exists.

This means that we can take any sequence \(\delta_n \to 0\) and produce
sets \(A_n\) such \(m(A) < \delta_n\) but \(\mu(A) > \varepsilon\).

So choose the sequence \(\delta_n = \frac 1 {2^n}\) and define \(A_n\)
accordingly, and let \begin{align*}
A = \limsup_n A_n = \intersect_{n=1}^\infty \union_{k = n}^\infty A_k
.\end{align*}

Since
\begin{align*}
\mu\left( \union_{k=n}^\infty A_k \right) \leq \sum_{k=n}^\infty \mu(A_k) \approx \frac {1}{2^n} \to 0,
\end{align*} by part (a) we have \(m(A) = 0\). Now by assumption, we
should thus have \(\mu(A) = 0\) as well.

However, again by part (a), we have \begin{align*}
\mu(A) = \lim_n \mu\left( \union_{k=n}^\infty A_k \right)
\geq \lim_n \mu(A_n) = \lim_n \varepsilon = \varepsilon > 0
.\end{align*}

\hypertarget{section-2}{%
\subsection{3}\label{section-2}}

Since \(f_k \to f\) almost everywhere, we have
\(\liminf_k f_k(x) = f(x)\) and since \(\abs{f}^2 \in L^+\) we can apply
Fatou:

\begin{align*}
\norm{f}_2^2
&= \int \abs{f(x)}^2  \\
&= \int \liminf_k \abs{f_k(x)}^2 \\
&\underset{\text{Fatou}}\leq\liminf_k \int \abs{f_k(x)}^2 \\
&= M^2
,\end{align*}

so \(\norm{f} \leq M < \infty\) and \(f\in L^2\).

Let \(I = [0, 1]\). Applying Egorov's theorem to produce sets
\(F_\varepsilon\) such that \(f_k\converges{u}\to f\) on
\(F_\varepsilon\) and taking \(F = \intersect F_\varepsilon\), we have
\begin{align*}
\int_I f_k 
&= \int_{F_\varepsilon}f_k + \int_{F_\varepsilon^c} f_k 
\quad \converges{\varepsilon \to 0}\to \quad 
\int_F f_k + 0 
\quad  \converges{k\to\infty}\to \quad 
\int_F f
,\end{align*} using that fact that uniform converges allows commuting
limits and integrals.

\hypertarget{section-3}{%
\subsection{4}\label{section-3}}

\hypertarget{a-2}{%
\subsubsection{a}\label{a-2}}

\(\implies\):

\begin{quote}
Idea:
\(\mathcal{A} = \theset{f(x) - t \geq 0} \intersect \theset{t \geq 0}\).
\end{quote}

Define \(F(x, t) = f(x)\), \(G(x, t) = t\), and
\(H(x, y) = F(x, t) - G(x, t)\), which are all measurable functions.

Then \(\mathcal{A} = \theset{H \geq 0} \intersect \theset{G \geq 0}\)
which is an intersection of measurable sets.

\(\impliedby\):

By F.T., for almost every \(x\in \RR^n\), the \(x\dash\)slices are
measurable, so \begin{align*}
\mathcal{A}_x \definedas \theset{t\in \RR \suchthat (x, t) \in \mathcal{A}} = [0, f(x)] \implies m(\mathcal A_x) = f(x)
\end{align*}

But \(x \mapsto m(\mathcal A_x)\) is a measurable function, and is
exactly to \(x \mapsto f(x)\), so \(f\) is measurable.

\hypertarget{b-2}{%
\subsubsection{b}\label{b-2}}

We first note \begin{align*}
\mathcal{A} &= \theset{(x, t) \in \RR^n\cross \RR \suchthat 0 \leq t \leq f(x)} 
\\
\mathcal{A}_t &= \theset{x
\in \RR^n \suchthat t\leq f(x) }
.\end{align*}

Then, \begin{align*}
\int_{\RR^n} f(x) ~dx 
&= \int_{\RR^n} \int_0^{f(x)} 1 ~dt~dx \\
&= \int_{\RR^n} \int_{\RR} \chi_\mathcal{A} ~dt~dx \\
&\overset{F.T.}= \int_{\RR} \int_{\RR^n} \chi_\mathcal{A} ~dx~dt\\
&= \int_0^\infty \int_{\RR^n} \chi_\mathcal{A} ~dx~dt\\
&= \int_0^\infty m(\mathcal{A}_t) ~dt
,\end{align*}

where we just note that \(\int \int \chi_\mathcal{A} = m(\mathcal{A})\),
and by F.T., all of these integrals are equal.

\hypertarget{section-4}{%
\subsection{5}\label{section-4}}

\hypertarget{a-3}{%
\subsubsection{a}\label{a-3}}

By Holder's inequality with \(p=q=2\), we have \begin{align*}
\norm{f}_1 = \norm{f\cdot 1}_1 \leq \norm{f}_2 \norm{1}_2 = \norm{f}_2 m(X)^{\frac 1 2} = \norm{f}_2,
\end{align*}

since \(X = [0, 1] \implies m(X) = 1\).

So \(L^2(X) \subseteq L^1(X)\), and since simple functions are dense in
both spaces, \(L^2\) is dense in \(L^1\).

\hypertarget{b-3}{%
\subsubsection{b}\label{b-3}}

\hypertarget{step-1}{%
\paragraph{Step 1}\label{step-1}}

Let \(\Lambda \in L^1(X)\dual\); we'll show that in fact
\(\Lambda \in L^2(X)\dual\), and by Riesz Representation for \(L^2\)
there will be a \(g\in L^2\) such that \(\Lambda(f) = \inner{f}{g}\).

\textbf{Lemma}: \(m(X) < \infty \implies L^p(X) \subset L^2(X)\).

\begin{quote}
\emph{Proof:} Write Holder's inequality as
\(\norm{fg}_1 \leq \norm{f}_a \norm{g}_b\) where
\(\frac 1 a + \frac 1 b = 1\), then \begin{align*}
\norm{f}_p^p = \norm{\abs f^p}_1 \leq \norm{\abs f^p}_a ~\norm{1}_b
.\end{align*}

Now take \(a = \frac 2 p\) and this reduces to \begin{align*}
\norm{f}_p^p &\leq \norm{f}_2^p ~m(X)^{\frac 1 b} \\
\implies \norm{f}_p &\leq \norm{f}_2 \cdot O(m(X)) < \infty
.\end{align*}
\end{quote}

Let \(f\in L^2\) be arbitrary -- by the lemma,
\(\norm{f}_1 \leq C\norm{f}_2\) for some constant \(C = O(m(X))\).

Since
\(\norm{\Lambda}_{1\dual} \definedas \displaystyle\sup_{\norm{f}_1 = 1} \abs{\Lambda(f)}\),
given an arbitrary \(f\in L^1\), we can define
\(\hat f = f/\norm{f}_1\), so \(\norm{\hat f}_1 = 1\), and obtain

\begin{align*}
\abs{\Lambda(\hat f)} \leq \norm{\Lambda}_{1\dual}
,\end{align*}

since \(\norm{\Lambda}_{1\dual}\) is the \emph{least} such bound over
all \(f\in L^1\), and thus

\begin{align*}
\frac{\abs{\Lambda(f)}}{\norm{f}_1} &= \abs{\Lambda(\hat f)} \leq \norm{\Lambda}_{1\dual} \\
\implies \abs{\Lambda(f)} 
&\leq \norm{\Lambda}_{1\dual} \cdot \norm{f}_1 \\
&\leq \norm{\Lambda}_{1\dual} \cdot C \norm{f}_2 
,\end{align*}

which is finite by assumption. So \(\Lambda \in (L^2)\dual\) since it is
bounded and thus continuous.

By Riesz Representation for \(L^2\), there is a \(g \in L^2\) such that
for all \(f\in L^2\), \(\Lambda(f) = \inner{f}{g}\)

\hypertarget{step-2}{%
\paragraph{Step 2}\label{step-2}}

By Holder, we already have

\begin{align*}
\norm{\Lambda}_{1\dual} 
&= \sup_{\norm{f}_1 = 1} \abs{\Lambda(f)} \\
&= \sup_{\norm{f}_1 = 1} \abs{\int_X fg} \\
&\leq \sup_{\norm{f}_1 = 1} \norm{fg}_1 \\
&\leq \sup_{\norm{f}_1 = 1} \norm{f}_1 \norm{g}_\infty \\
&= \norm{g}_\infty
,\end{align*}

so it just remains to show that
\(\norm{g}_\infty \leq \norm{\Lambda}_{1\dual}\).

Suppose otherwise, so \(\norm{g}_\infty > \norm{\Lambda}_{1\dual}\).

Then there exists some \(E\subseteq X\) with \(m(E) > 0\) such that
\(x\in E \implies \abs{g(x)} > \norm{\Lambda}_{1\dual}\).

Define \begin{align*}
h = \frac{1}{m(E)} \frac{\overline{g}}{\abs g} \chi_E
.\end{align*}

\begin{align*}
\Lambda(h) &= \int_X hg \\
&= \int_X \frac{1}{m(E)} \frac{g \overline g}{\abs g} \chi_E \\
&= \frac{1}{m(E)} \int_E \abs{g} \\
&\geq \frac{1}{m(E)} \norm{g}_\infty m(E) \\
&= \norm{g}_\infty \\
&> \norm{\Lambda}_{1\dual}
,\end{align*}

a contradiction.

\(\qed\)

%\listoftodos

\bibliography{/home/zack/Notes/library.bib}

\end{document}
